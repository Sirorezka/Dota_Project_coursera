{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import scipy\n",
    "import sklearn\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check of shapes\n",
      "(97230, 102)\n",
      "(17177, 102)\n"
     ]
    }
   ],
   "source": [
    "# 0. Import and prepare data for gradient boosting\n",
    "features = pandas.read_csv('../data/features.csv', index_col='match_id') \n",
    "features_test = pandas.read_csv('../data/features_test.csv', index_col='match_id') \t\n",
    "\n",
    "y_train = features[['radiant_win']] # target (question 4)\n",
    "x_train = features.drop(features.columns[102:], axis=1) # drop columns after 'duration' should be removed (question 1)\n",
    "x_test = features_test\n",
    "#print(x_train.head())\n",
    "print(\"Check of shapes\")\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with empty cells\n",
      "['first_blood_time' 'first_blood_team' 'first_blood_player1'\n",
      " 'first_blood_player2' 'radiant_bottle_time' 'radiant_courier_time'\n",
      " 'radiant_flying_courier_time' 'radiant_first_ward_time' 'dire_bottle_time'\n",
      " 'dire_courier_time' 'dire_flying_courier_time' 'dire_first_ward_time']\n"
     ]
    }
   ],
   "source": [
    "# check missing values\n",
    "countval_ind = np.where(x_train.count()-len(x_train) != 0)\n",
    "print(\"Columns with empty cells\")\n",
    "print(x_train.columns.values[countval_ind])\n",
    "\n",
    "# first_blood_time, first_blood_team, first_blood_player1, first_blood_player2, radiant_bottle_time, \n",
    "# radiant_courier_time, radiant_flying_courier_time, radiant_first_ward_time, dier_botle_time, \n",
    "# dire_courier_time, dire_flying_courier_time, dire_first_ward_time\n",
    "# -- команды могли не приобретать предметы bottle или courier в течение первых 5 минут, поэтому это не отражено в данных (question 2)\n",
    "\n",
    "x_train.fillna(10**(-6), inplace=True) # replacement (question 3)\n",
    "x_test.fillna(10**(-6), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "num_est = [10]\n",
    "for n in num_est:\n",
    "    clf_boost = ensemble.GradientBoostingClassifier(n_estimators = n, verbose = False) # max_depth можно ограничить\n",
    "    start_time = datetime.datetime.now()\n",
    "    this_time = datetime.datetime.now() - start_time\n",
    "    these_scores = cross_validation.cross_val_score(clf_boost, x_train, y_train, cv = kf, scoring = 'roc_auc')\n",
    "    scores[n] = np.mean(these_scores)\n",
    "    calctime[n] = np.sum(this_time)\n",
    "    print (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "Scores and time for Gradient Boosting\n",
      "               0\n",
      "scores       NaN\n",
      "10      0.664541\n",
      "20      0.681902\n",
      "30      0.689847\n",
      "                   0\n",
      "time             NaT\n",
      "10   00:00:10.808937\n",
      "20   00:00:17.989764\n",
      "30   00:00:26.226191\n"
     ]
    }
   ],
   "source": [
    "# 1. Gradient Boosting\n",
    "from sklearn import cross_validation\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = pandas.DataFrame(index=range(1),columns=['scores'])\n",
    "calctime = pandas.DataFrame(index=range(1),columns=['time'])\n",
    "\n",
    "#learning rate by default = 0.1 # checked different values from [1.0, 0.5, 0.3, 0.2, 0.1]\n",
    "\n",
    "kf = cross_validation.KFold (n = np.shape(x_train)[0], n_folds = 5, shuffle = True)\n",
    "num_est = [10, 20, 30] # checked other values as well, still got very bad score on Kaggle\n",
    "for n in num_est:\n",
    "    clf_boost = ensemble.GradientBoostingClassifier(n_estimators = n, verbose = False) # max_depth можно ограничить\n",
    "    start_time = datetime.datetime.now()\n",
    "    time.sleep(3)   ###  -- ошибка - лишнее замедление на 3 секунды\n",
    "    clf_boost.fit(x_train, y_train)  ###  -- ошибка - этого делать не надо\n",
    "    this_time = datetime.datetime.now() - start_time\n",
    "    these_scores = cross_validation.cross_val_score(clf_boost, x_train, y_train, cv = kf, scoring = 'roc_auc')\n",
    "    scores[n] = np.mean(these_scores)\n",
    "    calctime[n] = np.sum(this_time)\n",
    "    print (n)\n",
    "\n",
    "print(\"Scores and time for Gradient Boosting\")\n",
    "from pandas import DataFrame \n",
    "print(DataFrame.transpose(scores)) \n",
    "print(DataFrame.transpose(calctime)) # for n_estimators = 30 run-time is 35 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Logistic regression\n",
    "\n",
    "# Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Regression itself\n",
    "from sklearn import cross_validation\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "y_train_arr = np.ravel(y_train)\n",
    "\n",
    "scores = pandas.DataFrame(index=range(1),columns=['scores'])\n",
    "calctime = pandas.DataFrame(index=range(1),columns=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores and time for Logistic Regression\n",
      "               0\n",
      "scores       NaN\n",
      "0.001   0.716156\n",
      "0.01    0.716352\n",
      "0.1     0.716335\n",
      "1.0     0.716332\n",
      "10.0    0.716332\n",
      "100.0   0.716332\n",
      "1000.0  0.716332\n",
      "                     0\n",
      "time               NaT\n",
      "0.001  00:00:04.494373\n",
      "0.01   00:00:05.055713\n",
      "0.1    00:00:05.165859\n",
      "1.0    00:00:05.209585\n",
      "10.0   00:00:05.224672\n",
      "100.0  00:00:05.087375\n",
      "1000.0 00:00:05.102812\n"
     ]
    }
   ],
   "source": [
    "kf = cross_validation.KFold (n = np.shape(x_train)[0], n_folds = 5, shuffle = True)\n",
    "params = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0] # to select optimal C\n",
    "for p in params:\n",
    "    clf_log = linear_model.LogisticRegression(penalty='l2', C = p) # L2 regularization\n",
    "    start_time = datetime.datetime.now()\n",
    "    time.sleep(3)\n",
    "    clf_log.fit(x_train_scaled, y_train_arr)\n",
    "    this_time = datetime.datetime.now() - start_time\n",
    "    these_scores = cross_validation.cross_val_score(clf_log, x_train_scaled, y_train_arr, cv = kf, scoring = 'roc_auc')\n",
    "    scores[p] = np.mean(these_scores)\n",
    "    calctime[p] = np.sum(this_time)\n",
    "    print (p)\n",
    "    \n",
    "print(\"Scores and time for Logistic Regression\")\n",
    "print(DataFrame.transpose(scores))  # Best score = 0.72\n",
    "print(DataFrame.transpose(calctime)) # работает быстрее\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores without categorical variables\n",
      "               0\n",
      "scores       NaN\n",
      "0.001    0.71623\n",
      "0.01    0.716433\n",
      "0.1     0.716412\n",
      "1.0     0.716409\n",
      "10.0    0.716409\n",
      "100.0   0.716409\n",
      "1000.0  0.716409\n"
     ]
    }
   ],
   "source": [
    "# Remove categorical variables\n",
    "x_train = x_train.drop(['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero','d1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis=1)\n",
    "x_test = x_test.drop(['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero','d1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis=1)\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Re-estimate the model without categorical variables\n",
    "params = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0] \n",
    "for p in params:\n",
    "    clf_log = linear_model.LogisticRegression(penalty='l2', C = p)\n",
    "    clf_log.fit(x_train_scaled, y_train_arr)\n",
    "    these_scores = cross_validation.cross_val_score(clf_log, x_train_scaled, y_train_arr, cv = kf, scoring = 'roc_auc')\n",
    "    scores[p] = np.mean(these_scores)\n",
    "\n",
    "print(\"Scores without categorical variables\")\n",
    "print(DataFrame.transpose(scores))  # After removal the score is slightly (in 0.01) better (question 3), because of noise exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique heroes\n",
      "108\n",
      "Check sizes for heroes\n",
      "(97230, 112)\n",
      "(17177, 112)\n",
      "(97230, 203)\n",
      "(17177, 203)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find # of unique heroes\n",
    "allheroes = features[['r1_hero','r2_hero', 'r3_hero', 'r4_hero', 'r5_hero','d1_hero','d2_hero', 'd3_hero', 'd4_hero', 'd5_hero']]\n",
    "unique = np.unique(allheroes)\n",
    "print(\"Unique heroes\")\n",
    "print(np.shape(unique)[0]) # Number of unique heroes = 108 (question 4)\n",
    "\n",
    "# Add heroes \n",
    "countheroes = 112 # 108 непустых (использованных в обучающей выборке) героев\n",
    "x_pick_train = np.zeros((x_train.shape[0], countheroes))\n",
    "for i, match_id in enumerate(x_train.index):\n",
    "    for p in range(1,5):\n",
    "        x_pick_train[i, features.ix[match_id, 'r%d_hero' % p] -1] = 1\n",
    "        x_pick_train[i, features.ix[match_id, 'd%d_hero' % p] -1] = -1\n",
    "\n",
    "print(\"Check sizes for heroes\")\n",
    "print(np.shape(x_pick_train))\n",
    "\n",
    "x_pick_test = np.zeros((x_test.shape[0], countheroes))\n",
    "for i, match_id in enumerate(x_test.index):\n",
    "    for p in range(1,5):\n",
    "        x_pick_test[i, features_test.ix[match_id, 'r%d_hero' % p] -1] = 1\n",
    "        x_pick_test[i, features_test.ix[match_id, 'd%d_hero' % p] -1] = -1\n",
    "print(np.shape(x_pick_test))\n",
    "\n",
    "x_train_scaled_df = DataFrame(data = x_train_scaled, index = range(np.shape(x_train_scaled)[0]))\n",
    "x_pick_train_df = DataFrame(data = x_pick_train, index = range(np.shape(x_pick_train)[0]))\n",
    "x_train_scaled_full = pandas.concat([x_train_scaled_df, x_pick_train_df], axis = 1)\n",
    "print(np.shape(x_train_scaled_full))\n",
    "\n",
    "x_test_scaled_df = DataFrame(data = x_test_scaled, index = range(np.shape(x_test_scaled)[0]))\n",
    "x_pick_test_df = DataFrame(data = x_pick_test, index = range(np.shape(x_pick_test)[0]))\n",
    "x_test_scaled_full = pandas.concat([x_test_scaled_df, x_pick_test_df], axis = 1)\n",
    "print(np.shape(x_test_scaled_full))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores after adding heroes\n",
      "               0\n",
      "scores       NaN\n",
      "0.001   0.738755\n",
      "0.01    0.743715\n",
      "0.1     0.743926\n",
      "1.0     0.743913\n",
      "10.0    0.743911\n",
      "100.0   0.743911\n",
      "1000.0  0.743911\n",
      "Minumum and maximum values\n",
      "0.00322667129859\n",
      "0.996773328701\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Again ee-estimate the model\n",
    "params = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0] \n",
    "for p in params:\n",
    "    clf_log = linear_model.LogisticRegression(penalty='l2', C = p)\n",
    "    clf_log.fit(x_train_scaled_full, y_train_arr)\n",
    "    these_scores = cross_validation.cross_val_score(clf_log, x_train_scaled_full, y_train_arr, cv = kf, scoring = 'roc_auc')\n",
    "    scores[p] = np.mean(these_scores)\n",
    "\n",
    "print(\"Scores after adding heroes\")\n",
    "print(DataFrame.transpose(scores))  # После добавления \"мешка слов\" качество улучшилось, мы используем больше информации, которая оказывает значимое влияние на предсказание. Качество на кросс-валидации примерно 0.744\n",
    "\n",
    "clf_log = linear_model.LogisticRegression(penalty='l2', C = 0.1)\n",
    "clf_log.fit(x_train_scaled_full, y_train_arr)\n",
    "predictions = clf_log.predict_proba(x_test_scaled_full)\n",
    "print(\"Minumum and maximum values\")\n",
    "print(np.min(predictions))\n",
    "print(np.max(predictions))\n",
    "\n",
    "pd = pandas.DataFrame(predictions)\n",
    "pd.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
